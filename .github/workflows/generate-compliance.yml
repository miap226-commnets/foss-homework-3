name: FOSS Homework Automation

on: [push, workflow_dispatch]

jobs:
  generate-files:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Download zlib Source Code
        run: |
          wget --user-agent="Mozilla/5.0" https://www.zlib.net/zlib-1.3.1.tar.gz
          tar -xzvf zlib-1.3.1.tar.gz
          mv zlib-1.3.1 source_code

      - name: Generate SBOM with Syft
        uses: anchore/sbom-action@v0
        with:
          path: ./source_code
          format: spdx-json
          output-file: zlib_sbom.spdx.json

      # Step 3: [Python æ™ºèƒ½ä¿®å¤ç‰ˆ] ç»Ÿè®¡ Distinct Copyright
      # ä¿®å¤é€»è¾‘ï¼šé‡åˆ° URL æ—¶åªæ“¦é™¤ URLï¼Œä¿ç•™å‰é¢çš„äººåï¼›åŒæ—¶æ·±åº¦æ¸…æ´—ç‰¹æ®Šç¬¦å·
      - name: Count Distinct Copyright Notices
        id: count_copyrights
        run: |
          echo "å¯åŠ¨ Python æ‰«æå¼•æ“ (V2)..."
          
          cat << 'EOF' > scan.py
          import os
          import re

          root_dir = './source_code'
          notices = set()
          
          # æ­£åˆ™ï¼šåŒ¹é… Copyright + å¹´ä»½
          # ä½¿ç”¨ DOTALL æ¨¡å¼è§£å†³è·¨è¡ŒåŒ¹é…é—®é¢˜
          regex = re.compile(r'Copyright[^0-9a-zA-Z]*?((?:19|20)\d{2}.*?)(?:\r|\n|$)', re.IGNORECASE | re.DOTALL)

          for subdir, dirs, files in os.walk(root_dir):
              for file in files:
                  filepath = os.path.join(subdir, file)
                  try:
                      with open(filepath, 'r', errors='ignore') as f:
                          content = f.read()
                          
                          for match in regex.finditer(content):
                              raw_body = match.group(1)
                              full_text = "Copyright " + raw_body
                              
                              # === æ¸…æ´—é€»è¾‘ ===
                              
                              # 1. [å…³é”®ä¿®å¤] æ“¦é™¤ URL (http/https/www)ï¼Œè€Œä¸æ˜¯ä¸¢å¼ƒæ•´è¡Œ
                              # åŒ¹é… (http...) æˆ– http... ç›´åˆ°ç©ºæ ¼ç»“æŸ
                              clean = re.sub(r'\(?\s*https?://\S+', '', full_text, flags=re.IGNORECASE)
                              clean = re.sub(r'\(?\s*www\.\S+', '', clean, flags=re.IGNORECASE)
                              
                              # 2. æ¸…æ´—ç‰¹æ®Šç¬¦å· (æ–°å¢ /, {, }, [, ], - )
                              clean = re.sub(r'<[^>]*>', '', clean)
                              # æ³¨æ„ï¼šä¿ç•™å¹´ä»½ä¸­é—´çš„æ¨ªæ ï¼Œå»æ‰å…¶ä»–ä½ç½®çš„å¹²æ‰°
                              clean = re.sub(r'[*#";\\/{}\[\]]', '', clean)
                              
                              # 3. æ ‡å‡†åŒ–ä¿®å¤
                              clean = re.sub(r'&amp;', '&', clean)
                              clean = re.sub(r'&#169;', '(C)', clean)
                              clean = re.sub(r'\(c\)', '', clean, flags=re.IGNORECASE)
                              clean = re.sub(r'\s+by\s+', ' ', clean, flags=re.IGNORECASE)
                              clean = re.sub(r'Corp\.', 'Corporation', clean, flags=re.IGNORECASE)
                              clean = re.sub(r'all rights reserved', '', clean, flags=re.IGNORECASE)
                              
                              # 4. å»æ‰è¡Œå°¾çš„æ ‡ç‚¹ ( . , - ) å’Œé¦–å°¾ç©ºæ ¼
                              clean = re.sub(r'[,.-]\s*$', '', clean)
                              clean = re.sub(r'\s+', ' ', clean).strip()
                              
                              # 5. æœ€ç»ˆéªŒè¯ï¼šå¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªå­—æ¯
                              if re.search(r'[a-zA-Z]', clean):
                                  notices.add(clean)
                                  
                  except Exception:
                      pass

          with open('cleaned_notices.txt', 'w') as f:
              for n in sorted(notices):
                  f.write(n + '\n')
          EOF
          
          # è¿è¡Œè„šæœ¬å¹¶ç»Ÿè®¡
          python3 scan.py
          DISTINCT_COUNT=$(wc -l < cleaned_notices.txt)
          
          echo "============================================"
          echo "FINAL DISTINCT COUNT: $DISTINCT_COUNT"
          echo "============================================"
          
          echo "### ğŸ“Š æœ€ç»ˆç»Ÿè®¡ç»“æœ" >> $GITHUB_STEP_SUMMARY
          echo "- **Distinct Copyright Occurrences**: $DISTINCT_COUNT" >> $GITHUB_STEP_SUMMARY

      # Step 4: ç”Ÿæˆæ–‡ä»¶ (ä¸ Step 3 ä¿æŒå®Œå…¨ä¸€è‡´)
      - name: Generate Legal Notices File
        run: |
          echo "FOSS Homework 3 - Legal Notices" > LEGAL_NOTICES.txt
          echo "Student Matrikelnummer: (Fill in your ID)" >> LEGAL_NOTICES.txt
          echo "Project: zlib 1.3.1" >> LEGAL_NOTICES.txt
          # æ›´æ–°æè¿°ï¼šæŒ‡æ˜ä½¿ç”¨äº† Python è¿›è¡Œ URL ç§»é™¤å’Œæ ‡å‡†åŒ–
          echo "Tool used: GitHub Actions (Python script for URL removal & normalization)" >> LEGAL_NOTICES.txt
          echo "---------------------------------------------------" >> LEGAL_NOTICES.txt
          echo "" >> LEGAL_NOTICES.txt
          
          echo "DISTINCT COPYRIGHT NOTICES FOUND (NORMALIZED):" >> LEGAL_NOTICES.txt
          # [æ ¸å¿ƒ] ç›´æ¥ä½¿ç”¨ Step 3 æ¸…æ´—å¥½çš„æ–‡ä»¶
          cat cleaned_notices.txt >> LEGAL_NOTICES.txt
          
          echo "" >> LEGAL_NOTICES.txt
          echo "---------------------------------------------------" >> LEGAL_NOTICES.txt
          echo "RAW SCAN DETAILS (Reference only):" >> LEGAL_NOTICES.txt
          # ä»…ä¾›å‚è€ƒçš„åŸå§‹æ‰«æ
          grep -r -i -E "Copyright.*[0-9]{4}" ./source_code >> LEGAL_NOTICES.txt
          
          echo "" >> LEGAL_NOTICES.txt
          echo "--- Full License Context from README ---" >> LEGAL_NOTICES.txt
          cat ./source_code/README >> LEGAL_NOTICES.txt

      - name: Upload Homework Files
        uses: actions/upload-artifact@v4
        with:
          name: homework-submission-files
          path: |
            zlib_sbom.spdx.json
            LEGAL_NOTICES.txt
