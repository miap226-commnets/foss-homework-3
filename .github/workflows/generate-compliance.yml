name: FOSS Homework Automation

on: [push, workflow_dispatch]

jobs:
  generate-files:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Download zlib Source Code
        run: |
          wget --user-agent="Mozilla/5.0" https://www.zlib.net/zlib-1.3.1.tar.gz
          tar -xzvf zlib-1.3.1.tar.gz
          mv zlib-1.3.1 source_code

      - name: Generate SBOM with Syft
        uses: anchore/sbom-action@v0
        with:
          path: ./source_code
          format: spdx-json
          output-file: zlib_sbom.spdx.json

      # Step 3: [Python æœ€ç»ˆä¿®æ­£ç‰ˆ]
      # ä¿®å¤äº†æ­£åˆ™ BUGï¼šç°åœ¨å¯ä»¥æ­£ç¡®è¯†åˆ« Copyright (c) 1996 è¿™ç§åŒ…å«å­—æ¯ 'c' çš„å£°æ˜
      - name: Count Distinct Copyright Notices
        id: count_copyrights
        run: |
          echo "å¯åŠ¨ Python æ‰«æå¼•æ“ (Regex Fix)..."
          
          cat << 'EOF' > scan.py
          import os
          import re

          root_dir = './source_code'
          notices = set()
          
          # [æ ¸å¿ƒä¿®å¤]
          # æ—§æ­£åˆ™: r'Copyright[^0-9a-zA-Z]*?((?:19|20)\d{2}' -> é‡åˆ° (c) å°±å¤±è´¥
          # æ–°æ­£åˆ™: r'Copyright[^0-9]*?((?:19|20)\d{2}'      -> å…è®¸ (c), by ç­‰éæ•°å­—å­—ç¬¦
          # re.DOTALL è®© . åŒ¹é…æ¢è¡Œç¬¦ï¼Œè§£å†³è·¨è¡Œé—®é¢˜
          regex = re.compile(r'Copyright[^0-9]*?((?:19|20)\d{2}.*?)(?:\r|\n|$)', re.IGNORECASE | re.DOTALL)

          for subdir, dirs, files in os.walk(root_dir):
              for file in files:
                  filepath = os.path.join(subdir, file)
                  try:
                      with open(filepath, 'r', errors='ignore') as f:
                          content = f.read()
                          
                          for match in regex.finditer(content):
                              raw_body = match.group(1)
                              full_text = "Copyright " + raw_body
                              
                              # === æ¸…æ´—é€»è¾‘ ===
                              
                              # 1. æ“¦é™¤ URL (http/https/www)
                              # ç§»é™¤ç±»ä¼¼ ( http://... ) æˆ– http://...
                              clean = re.sub(r'\(?\s*https?://\S+\s*\)?', '', full_text, flags=re.IGNORECASE)
                              clean = re.sub(r'\(?\s*www\.\S+\s*\)?', '', clean, flags=re.IGNORECASE)
                              
                              # 2. æ¸…æ´—ç‰¹æ®Šç¬¦å·
                              clean = re.sub(r'<[^>]*>', '', clean)
                              # å»æ‰æ‹¬å·ã€å¼•å·ã€åˆ†å·ç­‰å¹²æ‰°
                              clean = re.sub(r'[*#";\\/{}\[\]]', '', clean)
                              
                              # 3. æ ‡å‡†åŒ–ä¿®å¤
                              clean = re.sub(r'&amp;', '&', clean)
                              clean = re.sub(r'&#169;', '(C)', clean)
                              clean = re.sub(r'\(c\)', '', clean, flags=re.IGNORECASE) # å»æ‰ (c)
                              clean = re.sub(r'\s+by\s+', ' ', clean, flags=re.IGNORECASE)
                              clean = re.sub(r'Corp\.', 'Corporation', clean, flags=re.IGNORECASE)
                              clean = re.sub(r'all rights reserved', '', clean, flags=re.IGNORECASE)
                              
                              # 4. å»æ‰è¡Œå°¾æ ‡ç‚¹ (.,-) å’Œå¤šä½™ç©ºæ ¼
                              clean = re.sub(r'[,.-]\s*$', '', clean)
                              clean = re.sub(r'\s+', ' ', clean).strip()
                              
                              # 5. éªŒè¯ï¼šå¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªå­—æ¯ï¼Œä¸”ä¸æ˜¯çº¯ä»£ç 
                              if re.search(r'[a-zA-Z]', clean) and len(clean) < 100:
                                  notices.add(clean)
                                  
                  except Exception:
                      pass

          with open('cleaned_notices.txt', 'w') as f:
              for n in sorted(notices):
                  f.write(n + '\n')
          EOF
          
          python3 scan.py
          DISTINCT_COUNT=$(wc -l < cleaned_notices.txt)
          
          echo "============================================"
          echo "FINAL DISTINCT COUNT: $DISTINCT_COUNT"
          echo "============================================"
          
          echo "### ğŸ“Š æœ€ç»ˆç»Ÿè®¡ç»“æœ" >> $GITHUB_STEP_SUMMARY
          echo "- **Distinct Copyright Occurrences**: $DISTINCT_COUNT" >> $GITHUB_STEP_SUMMARY

      # Step 4: ç”Ÿæˆæ–‡ä»¶
      - name: Generate Legal Notices File
        run: |
          echo "FOSS Homework 3 - Legal Notices" > LEGAL_NOTICES.txt
          echo "Student Matrikelnummer: (Fill in your ID)" >> LEGAL_NOTICES.txt
          echo "Project: zlib 1.3.1" >> LEGAL_NOTICES.txt
          echo "Tool used: GitHub Actions (Python script with Fixed Regex)" >> LEGAL_NOTICES.txt
          echo "---------------------------------------------------" >> LEGAL_NOTICES.txt
          echo "" >> LEGAL_NOTICES.txt
          
          echo "DISTINCT COPYRIGHT NOTICES FOUND (NORMALIZED):" >> LEGAL_NOTICES.txt
          # ä½¿ç”¨ Python ç”Ÿæˆçš„ä¿®æ­£åˆ—è¡¨
          cat cleaned_notices.txt >> LEGAL_NOTICES.txt
          
          echo "" >> LEGAL_NOTICES.txt
          echo "---------------------------------------------------" >> LEGAL_NOTICES.txt
          echo "RAW SCAN DETAILS (Reference only):" >> LEGAL_NOTICES.txt
          grep -r -i -E "Copyright.*[0-9]{4}" ./source_code >> LEGAL_NOTICES.txt
          
          echo "" >> LEGAL_NOTICES.txt
          echo "--- Full License Context from README ---" >> LEGAL_NOTICES.txt
          cat ./source_code/README >> LEGAL_NOTICES.txt

      - name: Upload Homework Files
        uses: actions/upload-artifact@v4
        with:
          name: homework-submission-files
          path: |
            zlib_sbom.spdx.json
            LEGAL_NOTICES.txt
